{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from logger import log, debug\n",
    "from cleaner import clean_corpus_basic, clean_corpus_standford\n",
    "from reader import read_files\n",
    "from lstm_utils import get_tokenizer, get_best_tokens_dummy\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Hiperparametros -----------------\n",
    "\n",
    "vector_size = 8\n",
    "each_q = 128\n",
    "batch_size = 2000\n",
    "epoch = 256\n",
    "min_lenght, max_length = 4, 8\n",
    "train_to_test = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Leyendo archivos en panda...]\n",
      "[Archivos Leidos...]\n",
      "[Usando cleaner basico]\n",
      "[Limpiando el corpus...]\n",
      "[Usando 8 threads ...]\n",
      "[El corpus tiene 20000 rows]\n",
      "[Luego de filtrar el corpus tiene 20000 rows]\n"
     ]
    }
   ],
   "source": [
    "# Leemos los archivos\n",
    "corpus = clean_corpus_basic(read_files(\"../dataset/\", [\"negative\", \"positive\"]))\n",
    "\n",
    "# Filtramos por longitud\n",
    "debug(\"[El corpus tiene \" + str(len(corpus)) + \" rows]\")\n",
    "\n",
    "#corpus[\"length\"] = corpus[\"content\"].map(lambda x: len(x.split(\" \")))\n",
    "#corpus = corpus[(corpus[\"length\"] >= min_lenght) & (corpus[\"length\"] <= max_length)]\n",
    "\n",
    "debug(\"[Luego de filtrar el corpus tiene \" + str(len(corpus)) + \" rows]\")\n",
    "\n",
    "#Shuffleamos el corpus\n",
    "corpus = shuffle(corpus)\n",
    "corpus.reset_index(inplace=True, drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Vectorizando corpus... ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "      <th>rate</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MAL MAL CALID NO PENS ERAN ASI</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>Malo Es muy mala calidad. No pensé que eran asi</td>\n",
       "      <td>negative</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MAL VIEN CABL NO VOLVERI COMPR HABI C0MPRAD0 O...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>malo Viene sin cable no la volveria a compran ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>EXCELENT BUEN CUMPL ESPECT</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>Excelente Muy buena, cumple con las espectativas</td>\n",
       "      <td>positive</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>PORQU RELOJ VENDEDOR MAL ECHO ESTE FALL PERMAN...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>Una porquería, el reloj y el vendedor. Es muy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INRESPONS HIC PREGUNT CUAL ERA MATERIAL TAP AF...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>Inresponsable Hice la pregunta de cual era el ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment  \\\n",
       "0                     MAL MAL CALID NO PENS ERAN ASI    [0, 1]   \n",
       "1  MAL VIEN CABL NO VOLVERI COMPR HABI C0MPRAD0 O...    [0, 1]   \n",
       "2                         EXCELENT BUEN CUMPL ESPECT    [1, 0]   \n",
       "3  PORQU RELOJ VENDEDOR MAL ECHO ESTE FALL PERMAN...    [0, 1]   \n",
       "4  INRESPONS HIC PREGUNT CUAL ERA MATERIAL TAP AF...    [0, 1]   \n",
       "\n",
       "                                                 raw      rate  \\\n",
       "0    Malo Es muy mala calidad. No pensé que eran asi  negative   \n",
       "1  malo Viene sin cable no la volveria a compran ...  negative   \n",
       "2   Excelente Muy buena, cumple con las espectativas  positive   \n",
       "3  Una porquería, el reloj y el vendedor. Es muy ...  negative   \n",
       "4  Inresponsable Hice la pregunta de cual era el ...  negative   \n",
       "\n",
       "                                              vector  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionamos los mejores tokens\n",
    "best_tokens = get_best_tokens_dummy(corpus, each_q)\n",
    "max_features = best_tokens.size\n",
    "\n",
    "tokenizer = get_tokenizer(best_tokens, vector_size)\n",
    "\n",
    "# Vectorizamos\n",
    "debug(\"[Vectorizando corpus... ]\")\n",
    "corpus['vector'] = tokenizer(corpus['content'])\n",
    "\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "best_tokens.to_pickle(\"best_tokens.bin\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Son 16000 train sequences]\n",
      "[Son 4000 test sequences]\n"
     ]
    }
   ],
   "source": [
    "# Dividimos el corpus\n",
    "\n",
    "x_total = np.stack(corpus[\"vector\"].values)\n",
    "y_total = np.stack(corpus['sentiment'].values)\n",
    "\n",
    "x_train, x_test = np.split(x_total, [int(train_to_test * len(x_total))])\n",
    "y_train, y_test = np.split(y_total, [int(train_to_test * len(x_total))])\n",
    "\n",
    "log(\"[Son \" + str(len(x_train)) + \" train sequences]\")\n",
    "log(\"[Son \" + str(len(x_test)) + \" test sequences]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Las neuronas van a ser: [21]]\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la cantidad de neuronas con las que vamos a procesar\n",
    "\n",
    "lstm_neurons = []#[int((2/3) * (2 + max_features))]\n",
    "\n",
    "for a in [4]:#range(2, 10 + 1):\n",
    "    dem = a * (2 + max_features )\n",
    "    lstm_neurons.append(int(len(x_train) / dem))\n",
    "\n",
    "lstm_neurons = list( dict.fromkeys(lstm_neurons) )\n",
    "\n",
    "log(\"[Las neuronas van a ser: \" + str(lstm_neurons) + \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "[Usando 21 neuronas]\n",
      "[Buildeando modelo... ]\n",
      "[Modelo buildeado]\n",
      "[Fiteando modelo... ]\n",
      "[Testeando modelo... ]\n",
      "[   Score: 0.15865857154130936\n",
      "[   Accuaracy: 0.949999988079071\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos modelo y testeamos\n",
    "\n",
    "lstm_results = []\n",
    "for neurons in lstm_neurons: \n",
    "    log(\"-----------------------\")\n",
    "    log(\"[Usando \" + str(neurons) + \" neuronas]\")\n",
    "\n",
    "    #Buildemos modelo\n",
    "    log(\"[Buildeando modelo... ]\")\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, dropout=0.2, input_shape=(vector_size, max_features)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    log(\"[Modelo buildeado]\")\n",
    "\n",
    "    # Fitteamos\n",
    "    log(\"[Fiteando modelo... ]\")\n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epoch,  \n",
    "              validation_data=(x_test, y_test),\n",
    "                verbose=0)\n",
    "    \n",
    "    \n",
    "    #Testeamos\n",
    "    log(\"[Testeando modelo... ]\")\n",
    "    score, acc = model.evaluate(x_test, y_test,\n",
    "                                batch_size=batch_size,\n",
    "                               verbose=0)\n",
    "    \n",
    "    log(\"[   Score: \" + str(score))\n",
    "    log(\"[   Accuaracy: \" + str(acc))\n",
    "    \n",
    "    lstm_results.append((neurons, score, acc, history))\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
